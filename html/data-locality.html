<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8" />

<title>Game Programming Patterns / Optimizing Patterns / Data Locality</title>

<!-- Tell mobile browsers we're optimized for them and they don't need to crop
     the viewport. -->
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<link rel="stylesheet" type="text/css" href="style.css" />
<link href="http://fonts.googleapis.com/css?family=Source+Code+Pro|Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-42804721-1', 'gameprogrammingpatterns.com');
  ga('send', 'pageview');
</script>
</head>
<body id="top">
<div class="content">
<h1 class="book"><a href="index.html">Game Programming Patterns</a> / Optimizing Patterns</h1>
<h1>Data Locality</h1>
<div class="in-progress">
  <span class="dismiss">&times;</span>
  <p><strong>This book is a work in progress!</strong></p>

  <p>If you see a mistake, find something unclear, or have a suggestion, please <a href="https://github.com/munificent/game-programming-patterns/issues/new" target="_blank">file a ticket</a>. To know when new chapters are up, join the mailing list:</p>

  <!-- Begin MailChimp Signup Form -->
  <div id="mc_embed_signup">
  <form action="http://gameprogrammingpatterns.us7.list-manage.com/subscribe/post?u=0952ca43ed2536d6717766b88&amp;id=0c27329244" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <table>
      <tr>
        <td width="100%">
          <input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
        </td>
        <td>
          <div class="spacer"></div>
        </td>
        <td>
          <input type="submit" value="Join" name="subscribe" id="mc-embedded-subscribe" class="button">
        </td>
      </tr>
    </table>
  </form>
  </div>
  <!--End mc_embed_signup-->

  <table width="100%">
    <tr>
      <td width="50%">
        <p>Thank you!</p>
      </td>
      <td width="50%">
        <p class="signature">&mdash; Bob (<a href="https://twitter.com/intent/user?screen_name=munificentbob" target="_blank">@munificentbob</a>)</p>
      </td>
    </tr>
  </table>
</div>
<h2><a href="#intent" name="intent">Intent</a></h2>
<p><em>Optimize processor cache utilization by arranging data in memory in the order that it is used.</em></p>
<h2><a href="#motivation" name="motivation">Motivation</a></h2>
<p>We&#x2019;ve all been lied to. For years, we&#x2019;ve been shown charts where CPU speed keeps going up and to the right. Moore&#x2019;s Law isn&#x2019;t just some historical observation, it&#x2019;s some kind of moral imperative. We software folks shouldn&#x2019;t have to lift a finger to see our programs magically speed up every year.</p>
<p>CPUs have been getting faster (though even that&#x2019;s plateauing now), but the hardware heads failed to mention a little something. Sure, we can process data faster than ever. But we can&#x2019;t <em>get</em> that data faster.</p>
<p><strong>TODO: graph of processor and memory speeds</strong></p>
<h3><a href="#a-data-warehouse" name="a-data-warehouse">A data warehouse</a></h3>
<p>Before your super fast CPU can blow through a ream of calculations, it actually needs to get the data its working on out of main memory and into registers. It turns out that RAM hasn&#x2019;t been keeping up with increasing CPU speeds. Not even close.</p>
<p>With today&#x2019;s typical hardware, it can take <em>hundreds</em> of cycles to fetch a byte of data from <span name="ram">RAM</span>. If each instruction needs some data, and it takes hundreds of cycles just to get a byte of data for that instruction, how is that our CPUs aren&#x2019;t just sitting idle 99% of the time waiting for data?</p>
<p>Actually, they <em>are</em> stuck waiting on memory an astonishingly large fraction of time these days, but it&#x2019;s not as bad as it could be. To explain how, we&#x2019;re going to take a trip to the Land of Overly Long Analogies&hellip;</p>
<aside name="ram">

<p>It&#x2019;s called "Random access memory" because, unlike disc drives, you can theoretically access any piece of it as quick as any other. You don&#x2019;t have to worry about reading things consecutively like you do a disc.</p>
<p>Or, at least, you <em>didn&#x2019;t</em>. As we&#x2019;ll see, RAM isn&#x2019;t so random access anymore either.</p>
</aside>

<p>Imagine you&#x2019;re an accountant in a tiny little office. Your job is to request a box of papers and go through and do some <span name="accountant">accountant</span>-y stuff with them. Add up a bunch of numbers or something. You do this for specific labeled boxes according to some arcane logic that only makes sense to other accountants.</p>
<aside name="accountant">

<p>I probably shouldn&#x2019;t have used a job I know absolutely nothing about in this analogy.</p>
</aside>

<p>You&#x2019;ve been working this job for a while and you&#x2019;ve gotten pretty awesome at it. You can now finish off an entire box of paper in, say, a minute. Impressive, right? On a good day without too many coffee breaks, you should be able to get through about 480 boxes.</p>
<p>There&#x2019;s a little problem though. All of those boxes are stored in a warehouse in a separate building. To get a box, you have to ask the warehouse guy to bring it to you. He goes and gets a forklift and drives around the aisles until he finds the box you want.</p>
<p>It takes him, seriously, an entire day to do this. Not exactly a go-getter. He&#x2019;s the boss&#x2019;s son, so no one&#x2019;s gonna do anything about it. This means that no matter how fast you are, you only get one box a day. The rest of the time, you just sit there and question the life decisions that led to this soul-sucking job instead of following your passion for videogames.</p>
<p>One day, a couple of industrial designers show up. Their job is to improve the efficiency of operations. They make assembly lines and stuff go faster. The boss has noticed how few boxes get processed and he wants some improvement, so he brought in the experts.</p>
<p>After watching you work for a few days, they notice a few things:</p>
<ul>
<li>
<p>Pretty often, when you&#x2019;re done with one box, the next box you request is right
  <span name="next">next</span> to it on the same shelf in the warehouse.</p>
</li>
<li>
<p>Using a forklift to carry a single box of papers is pretty dumb.</p>
</li>
<li>
<p>There&#x2019;s actually a little bit of spare room in the corner of your office.</p>
</li>
</ul>
<aside name="next">

<p>The technical term for often using stuff nearby the thing you just used is <em>locality of reference</em>.</p>
</aside>

<p>They come up with a clever fix. Whenever the warehouse guy gets a box, he&#x2019;ll
actually grab an entire pallet of them. He gets the box you requested, and then
a bunch of boxes that are next to it. He doesn&#x2019;t know if you want those (and, given his work ethic, clearly doesn&#x2019;t care). He just grabs them.</p>
<p>He loads the whole pallet and brings it to you. Ignoring issues of workplace safety, he drives the forklift right in and drops the pallet in the corner of your office.</p>
<p>When you need a new box, now, the first thing you do is see if it&#x2019;s already on the pallet in your office. If it is, great! It just takes you a second to grab it and you&#x2019;re back to crunching numbers. If a pallet holds fifty boxes and you got lucky and all of the boxes you need happen to be on it, you can churn through fifty times more work than you could before.</p>
<p>But, if you need a box that&#x2019;s <em>not</em> on the pallet, you&#x2019;re back to square one. You can only fit one pallet in your office, so your warehouse friend will have to come take that one back and then bring you entirely new one. Tomorrow.</p>
<h2><a href="#cpu-cache" name="cpu-cache">cpu cache</a></h2>
<p>very close analogy for how cpus work today. (why would it be in chapter if
wasn&#x2019;t good analogy?)</p>
<p>warehouse is main memory. fetching data from it is slooooow.</p>
<p>box is amount of data that fits in registers</p>
<p>but cpus now have a cache. small chunk of mem faster to access than ram.
fast because on chip. literally in area of computers where physics comes
into play. faster because electrons have less distance to travel.</p>
<p>in analogy, cache is pallet of boxes you can fit in your office</p>
<p>when cpu requests byte from main memory, it automatically grabs a chunk of
contiguous memory, usually 64 or 128 bytes. called "cache line". pulls that
whole line of data into cache at once.</p>
<p>if you read next byte of data after one you just requested, its already in
cache (on pallet in office) and its superfast.</p>
<p>actually multiple levels of cache. each bigger and slower and then next: l1,
l2, etc. different chips different.</p>
<p>when chip needs byte, if it&#x2019;s in cache, gets it fast. called
cache hit.</p>
<p>if not already in cache, have to go to ram (or next cache level). called
cache miss.</p>
<p>cache misses are the enemy.</p>
<p>imagine you&#x2019;re trying to optimize some code like this:</p>
<p _="
" actors_i_-_update_="actors[i]-&gt;update();
" doAbsolutelyNothingFor500Cycles_="doAbsolutelyNothingFor500Cycles();
">for (int i = 0; i &lt; NUM_ACTORS; i++)</p>
<p>what&#x2019;s the first thing you&#x2019;re going to do? right. that fn call is a cache
miss.</p>
<p>speed difference when reading from cache compared to memory is huge. think
100x or more. has huge impact on app perf.</p>
<p>[asked game dev friend what he knows about cache perf. said he spent most of past two years doing nothing but optimizing games for cache usage.]</p>
<h2><a href="#memory-=-perf" name="memory-=-perf">memory = perf?</a></h2>
<p>heard about importance of cache before writing this, but no first-hand
experience. (most my background higher level).</p>
<p>did some benchmarks.</p>
<p>surprisingly hard to write good test program to thrash cache and compare
worst case to best.</p>
<p>when i did, really surprised. got couple little programs and did variations of
them to change how they interacted with cache. worse case was 50 <em>times</em> slower than best.</p>
<p>doing exact same computation, exact same data, exact same results</p>
<p><em>only</em> difference was caching effects</p>
<p>[ymmv, heavily machine dependent]</p>
<p>tend to think of optimization on two axes: speed and memory usage</p>
<p>optimizations like memoization, caching, denormalization, etc. spend extra
memory to go faster</p>
<p>optimizations like compression trade in speed to save memory</p>
<p>sort of orthogonal, can spend one to get other</p>
<p>but tend to think of code being about speed and data being about memory usage</p>
<p>but surprising lesson for me here is data is about speed too!</p>
<p>book tries to be about concrete patterns. simple well-defined recipes.</p>
<p>optimization for cache usage is big topic. haven&#x2019;t even touched on instruction
cache - remember code is in ram too and has to be fetched onto cpu. caching
comes into play there too!</p>
<p>could write entire book</p>
<p>hard to come up with something simple for this chapter</p>
<p>if problem is lots of cache misses, solution is trying to keep the stuff you
need in cache lines you&#x2019;ve already loaded. [on same pallet in analogy]</p>
<p>lot of concrete ways for doing that, mention a couple. basic common idea idea
is to lay out data contiguously in memory in the
order you process it</p>
<p>if code is crunhing on a then b then c, then make your memory look like</p>
<div class="codehilite"><pre>  <span class="o">+---+---+---+</span>
  <span class="o">|</span> <span class="n">a</span> <span class="o">|</span> <span class="n">b</span> <span class="o">|</span> <span class="n">c</span> <span class="o">|</span>
  <span class="o">+---+---+---+</span>
</pre></div>


<p>note, not <em>pointers</em> to a, b, c. actual data, right there. if we just point
to it, have to follow that pointer, and now we&#x2019;re off in memory that&#x2019;s
unlikely to be in cache ("pointer chasing")</p>
<p>goal is to feed as many bytes to cpu in one contiguous chunk as possible.
sounds easy, but we&#x2019;ll see some challenges.</p>
<h2><a href="#the-pattern" name="the-pattern">The Pattern</a></h2>
<p>modern cpus are much slower to access memory following memory that was previously accessed. improve performance by organizing data contiguously in memory in order you process it.</p>
<h2><a href="#when-to-use-it" name="when-to-use-it">When to Use It</a></h2>
<p>have code that&#x2019;s performance critical</p>
<p>touches a lot of data</p>
<p>accessing main memory is slow</p>
<p>burning lots of cycles on data cache misses. profile profile profile!</p>
<p>in other words, make sure you have a real problem and you&#x2019;re certain problem
is coming from cache. as we&#x2019;ll see, this pattern can be major architectural
surgery. don&#x2019;t want to operate unless patient is really sick.</p>
<p>(other way to think about it is good to keep this pattern in mind throughout
project so don&#x2019;t have to make sweeping changes later for it.)</p>
<h2><a href="#keep-in-mind" name="keep-in-mind">Keep in Mind</a></h2>
<p>many optimizations sacrifice abstraction for speed. abstraction is about
building interfaces to obscure what&#x2019;s going on. that decoupling makes it
easier to change things without affecting other stuff. abstraction about
generalization, about being flexible by not making assumptions.</p>
<p>perf is often about the concrete. opt often starts with "assuming we only need
x" then takes advantage of that. thrives on specifics.</p>
<h3><a href="#anti-oop" name="anti-oop">Anti-OOP?</a></h3>
<p>this pattern in particular fights against encapsulation. in c++ going through
interfaces implies pointers and references. but this pattern is about putting
object in memory <em>here</em>, not <em>pointer to it</em>.</p>
<p>[virtual methods are other half of encapsulation. those cause similar caching
problems with i cache.]</p>
<p>to give cpu lots of data to chew, often means large collections of objects.
to have contiguous, usually need to be same size. means it works best with
objects of same type so they are same size. goes against subclassing where
objects may be different sizes.</p>
<h3><a href="#anti-object-but-pro-class" name="anti-object-but-pro-class">Anti-object but pro-class?</a></h3>
<p>oop is about treating object as independent actor that owns state and behavior.
naturally optimized for thinking of objects as owners of their own destiny
and singular.</p>
<p>this pattern really about aggregates. associates behavior with <em>collection</em>
of objects.</p>
<p>may feel unintuitive.</p>
<p>think we&#x2019;ll see that most of oop principles like data hiding are still there.
more about hiding data in <em>type</em>, not <em>instance of type</em>, which is actually
how priv in c++ works anyway.</p>
<p><strong>todo: above para may not pan out</strong></p>
<p><strong>todo: subheader?</strong></p>
<p>pattern often means moving stuff around in memory to keep stuff contiguous.
when moving stuff, have to be careful about pointers to things you&#x2019;re moving.
this is <em>not</em> easy pattern to apply.</p>
<h2><a href="#sample-code" name="sample-code">Sample Code</a></h2>
<p>confession time. wanted to show a single example here that was skeleton of game
loop processing a bunch of components. was going to show complete worst case
example with lots of pointer chasing, stuff random in memory. then show
optimized version so you could run yourself and see perf difference.</p>
<p>ended up being lesson in how tricky this opt. optimizing for cache <em>highly</em>
context-dependent. used to thinking that code composes. if you have piece of
code exhibits a and other exhibits b, slap together exhibits a and b.</p>
<p>but caching relies on big hidden complex chunk of mutable state (cpus caches
and the mapping it uses from memory to cache, prefetching logic etc.) means
two unrelated pieces of code can have wildly different cache effects when put
in program together.</p>
<p>good reminder of golden rule of programming: profile in the context of your
actual program.</p>
<p>managed to get some benchmarks that showed drastic effects on my computer, but
every time tried to put them into form that made sense interleaved with prose
in chapter, effects dimished. (not disappear! still could manifest 5x worse
perf.)</p>
<p>instead of trying to shoehorn both tight benchmark and good
teaching example into one program, doing something ultimately better. instead of single monolithic example, do a few
different smaller examples showing some of various techniques commonly applied
to make code more cache friendly.</p>
<h3><a href="#contiguous-arrays" name="contiguous-arrays">contiguous arrays</a></h3>
<p>typical game loop using component pattern. have bunch of actors. each actor has
ai, physics, and render component. here&#x2019;s what <em>needs</em> to happen (in order):</p>
<ol>
<li>update all of ai components.</li>
<li>update all of physics components.</li>
<li>render all render components.</li>
</ol>
<p>lot of game engines look like:</p>
<div class="codehilite"><pre><span class="n">naive</span> <span class="n">pointer</span> <span class="n">chasing</span>
</pre></div>


<p>we are murdering cache here. after running this code, cache actively hates us.
spitting in coffee. here&#x2019;s what doing wrong.</p>
<ol>
<li>iterating over list of actors. list of pointers to actors.</li>
<li>for each actor, traverse pointer. CACHE MISS.</li>
<li>now look up physics component in actor.</li>
<li>that&#x2019;s pointer too. traverse CACHE MISS.</li>
<li>update physics component.</li>
<li>go all the way back to list of actor pointers and start again.</li>
</ol>
<p>since actors and components are pointers, could be scattered all over memory.
especially since actors created destroyed during game, often are arranged
randomly.</p>
<p>observe: only reason we look up actor is to get to component. actor itself has
no interesting data. also, order we update components doesn&#x2019;t usually matter.
sure, can make difference in game, but not usually one that matters to player.</p>
<p>instead of huge tree of actors and components spread over memory, simplify:
one array of components for each type. big array of ai, physics components, etc.
not array of pointers, array of actual objects. not linked list. ARRAY.</p>
<p>game loop tracks arrays directly. when it updates ai, just walks ai component
array and updates each one in turn. no pointer chasing. no skipping around
memory. pumping delicious bytes of data directly into cpu&#x2019;s hungry maw. happy
cpu.</p>
<p>do this for each component type. then done. in little synthetic benchmark,
made 50x diff.</p>
<p>interestingly, note that this doesn&#x2019;t break encapsulation. each component still
owns its data and behavior. data is still private. just changed way its used.</p>
<p>actor can even maintain pointers to its components. if you have actor and need
to get to component from it, can still have that capability. important part is
that hot processing loop can sidestep and go straight to data.</p>
<h3><a href="#packed-data" name="packed-data">packed data</a></h3>
<p>ok, so you reorganize codebase around above pattern. makes lots of sense when
you have fixed set of actors, but actors come and go. maybe actors far from
player are deactivated and don&#x2019;t get processed.</p>
<p>end up doing</p>
<div class="codehilite"><pre><span class="n">iterate</span> <span class="n">over</span> <span class="n">components</span> <span class="n">and</span> <span class="n">check</span> <span class="n">is</span> <span class="n">active</span>
</pre></div>


<p>two problems. first is now we have to look up actor and check flag. constantly
switching between reading memory from actor and the memory from component.
thrash cache.</p>
<p>second problem is when actor is inactive, end up skipping over component data.
with lots of inactive actors, constantly blowing cache skipping through memory
looking for something that actually needs updating.</p>
<p>solution is instead of <em>checking</em> active flag, <em>sort</em> by it. keep all active
actors in front of list. then track how many there are. update loop is simple</p>
<div class="codehilite"><pre><span class="n">loop</span> <span class="n">active</span> <span class="n">components</span>
</pre></div>


<p>trick is keeping sorted. actors change active state all time. to keep memory
packed, can do this:</p>
<div class="codehilite"><pre><span class="mf">1.</span> <span class="n">when</span> <span class="n">actor</span> <span class="n">is</span> <span class="n">activated</span><span class="p">,</span> <span class="n">swap</span> <span class="n">memory</span> <span class="k">for</span> <span class="n">its</span> <span class="n">component</span> <span class="n">with</span> <span class="n">first</span>
<span class="n">inactive</span> <span class="n">component</span> <span class="n">in</span> <span class="n">list</span><span class="p">,</span> <span class="n">the</span> <span class="n">inc</span> <span class="n">number</span> <span class="n">of</span> <span class="n">active</span> <span class="n">actors</span><span class="p">.</span>
<span class="mf">2.</span> <span class="n">when</span> <span class="n">deactivated</span><span class="p">,</span> <span class="n">swap</span> <span class="n">memory</span> <span class="k">for</span> <span class="n">its</span> <span class="n">component</span> <span class="n">with</span> <span class="n">last</span> <span class="n">active</span> <span class="n">component</span>
<span class="n">then</span> <span class="n">dec</span> <span class="n">num</span>
</pre></div>


<p>lots of programmers allergic to moving stuff in memory. feels heavyweight.
but move is just read and write. not much slower than just reading it, which
do every frame. if active states change less often than you update, then
probably quicker to take hit of moving things to keep sorted if it keeps update
loop fast. profile!</p>
<h3><a href="#hotcold-splitting" name="hotcold-splitting">hot/cold splitting</a></h3>
<p>this is a bit like a finer-grained manifestation of previous example. say we&#x2019;ve
got ai component for actor. has a few fields for basic pathfinding, and which
target actor is heading towards. stuff it uses every single frame.</p>
<p>but also some ai data for less common scenarios. maybe has some data to store
what item it drops when killed. that state will only come in to play once.</p>
<p>if updating bunch of actors ai, walking through nicely packed components, but
still wasting a bunch of time skipping over state we aren&#x2019;t using every frame.
all of data for drop is getting loaded into cache for no reason. end up getting
more cache misses since data we do care about is more spread out.</p>
<p>solution is called hot/cold splitting. slice ai component into two structures.
first holds "hot data": fields we need every frame. second is cold data.</p>
<p>hot component holds pointer to cold one. when we need cold data, can get to it
through that. other wise, only have to skip over pointer when iterating over
components. (if using parallel arrays like first example, could even possible
ditch pointer.)</p>
<p>can see how this starts to get fuzzy. deciding which data is hot and cold
depends a lot on game and how it gets used. more art than science. maybe not
even art. crapshoot?</p>
<h2><a href="#design-decisions" name="design-decisions">Design Decisions</a></h2>
<p>pattern is really about a mindset: getting you to think about where stuff is in
memory as a critical piece of performance story. actual concrete design space
is wide open. can affect every corner of codebase and architect deeply around
this ("data-oriented design"). or maybe just local opt you do for some key stuff
like render loop and particles.</p>
<h3><a href="#what-is-granularity-of-classes" name="what-is-granularity-of-classes">what is granularity of classes?</a></h3>
<p>lot of oop teaches us to define small fine-grained classes with has-a references to other objects. get bit trees or graphs of tiny objects scattered in memory. nice for separation of concerns and reuse. not nice for keeping things contiguous.</p>
<p>don&#x2019;t have to give up encapsulation, but sometimes makes more sense to think of class as representing collection of homogeneous objects. instead of particle class, have particle <em>system</em> class. often what&#x2019;s going on when you see "manager", "system", or "pool": single instance of class that represents large number of things.</p>
<p><strong>class = individual object:</strong></p>
<ul>
<li>
<p><em>how we&#x2019;ve been trained to do object modeling.</em> lets you bring into play all of powerful abstraction and encapsulation tools oop gives us. makes it easier to reason about behavior and state of small individual entities in isolation. while not perfect, reason this is most successful paradigm in world.</p>
</li>
<li>
<p><em>perfectly adequate for most of codebase.</em> opt triggers some weird flaw in brain where once start worrying about perf, hard to <em>stop</em> wanting to optimize everything. get obsessed.
   but opt isn&#x2019;t without cost. get too sucked into perf mindset and can end up sacrificing all manner of things at that altar. like maintainability and flexibility. takes time too. dumb to burn time optimizing 80% of codebase that is not perf critical. your menu screens probably don&#x2019;t need to worry about this.</p>
</li>
</ul>
<p><strong>manager objects:</strong></p>
<ul>
<li>
<p><em>for lightweight "dumb" objects, don&#x2019;t lose much by having object that represents group of them.</em> things like particles where behavior of every particle is conceptually same are just as easy to reason about in class that updates a pile of them as they are in class that only deals with one.</p>
</li>
<li>
<p><em>lets manager completely control memory for objects.</em> weird that with most objects, they don&#x2019;t encapsulate their own memory management. [operator new] memory has to be given to them before they come to life. to keep stuff in right place in memory, you need some manager <em>anyway</em>, so it may as well manage the objects as well as their memory.</p>
</li>
<li>
<p><em>lets you control access to objects</em>. by hiding individual objects behind manager, you can prevent outside code from getting raw pointer to them. very important if you are sorting, packing or otherwise moving in memory: doing so would break any existing pointers.</p>
</li>
</ul>
<p><strong>both:</strong></p>
<p>final option is to do both: have class for manager and class for individual objects. if doing manager, will end up doing this in some way anyway. at very least, will have dumb struct for individual object. once have that, have option of putting some methods there too for things that only operate on single object.</p>
<p>classes will likely end up being very closely tied to each other. friend in c++.</p>
<ul>
<li>
<p><em>gets you back some of encapsulation of individual objects.</em> at least some of behavior can be scope to single object.</p>
</li>
<li>
<p><em>most complex.</em> have two full classes. have to decide which has which parts of responsibility.</p>
</li>
</ul>
<h3><a href="#how-are-actors-defined" name="how-are-actors-defined">how are actors defined?</a></h3>
<p>if using nice contiguous arrays of components and iterating them directly,
actual actor object is less important during core game loop. still useful in other places in codebase that want to work with single logical "actor".</p>
<p>question is how should it be represented? how does it track its components?</p>
<p><strong>inline:</strong></p>
<p>if actor has components as actual fields and not pointers to components (or not using explicit component pattern at all), then data stored inline in actor object. in other words, not using optimizing components in memory for updating.</p>
<p><em>can move entire actor in memory.</em> since actor and its components are now all
  one contiguous obj, can move whole thing around without worrying about fragmenting it.</p>
<p><em>faster to access all actor data.</em> splitting actors into components optimizes for use case where you access all components of bunch of actors at same time. but if your access pattern is for touching all data for one actor at same time, this better. localizes actor data together.</p>
<p><em>simpler, smaller:</em> don&#x2019;t have to manage memory for pieces of actor separately. don&#x2019;t waste space storing pointers.</p>
<p><strong>pointers:</strong></p>
<p>kind of typical oop solution. actor has raw pointers to its components.</p>
<p><em>can store components in contiguous arrays.</em> since actor no longer cares where component is,
  can actuall physically be in obj pool, so iterating over components is nice to cache. at same time, actor can still easily get to its components.</p>
<p><em>makes moving components hard.</em> if sorting or packing components in memory to keep cache filled, pointers in actor will break if you&#x2019;re not careful to update them.</p>
<p>*<em>handles or smart pointer:</em></p>
<p>more refined solution is some kind of "handle" or custom pointer type. still references component stored elsewhere, but can include some additional tracking info. in particular, lets you keep track of all existing pointers into some component.</p>
<p><em>more complex</em>: smart pointers aren&#x2019;t rocket science, but aren&#x2019;t trivial either.
  <em>can handle moving components</em>: if have way of finding all handles to some component, can move component in memory and have handles update to new location.</p>
<div class="codehilite"><pre>  <span class="o">**</span><span class="n">Todo</span><span class="o">:</span> <span class="n">code</span><span class="o">**</span>
</pre></div>


<p><strong>actors as id:</strong></p>
<p>new style some engines use. imagine have contiguous arrays for each component type. now say components are stored in same order in each array. so ai component for some actor will be in third slot in ai component array, and render component for that actor will be in third slot in render component array, etc.</p>
<p>at this point, number 3 is all you need to find all components for an actor. so can turn actor class into just a simple id. becomes tiny! to get component for some actor, pass it (i.e. actor itself) to manager for some component. it uses id to look up index in array.</p>
<p><em>actors are tiny</em> just little ids, no pointers or anything.</p>
<p><em>actors are tiny</em>. downside is can&#x2019;t store other data on actor. really have to double down
  on pushing things into components.</p>
<p><em>works best when all actors have same set of components.</em> good thing about component pattern is allows mix-and-match. invisible object can just not have render component. immovable object can not have ai component. but if id describes index in parallel component arrays, those arrays need to be parallel to keep things lined up.</p>
<p>if actor doesn&#x2019;t have render component, still have to claim a slot in array so that later actors render components are in right position. can have inactive components to handle this. but means update loop will have to skip over memory for unused components.</p>
<p><em>can&#x2019;t sort components independently.</em> since single id identifies component for actor in all arrays, can&#x2019;t sort one component array to keep things packed without sorting others in parallel. if, for example, active states for different components vary, can&#x2019;t keep each one sorted according to its own needs. very tighltly parallel arrays.</p>
<p><em>can&#x2019;t move components</em> of course, not only can&#x2019;t move them independently, can&#x2019;t move them at all. since actor id is direct index into array, moving component invalidates id. instead,
  engines keep track of unused ids. when actors are added and removed, instead of moving others around, just allows holes for unused ids in list and fills them in later.</p>
<p>see object pool for more details.</p>
<h2><a href="#see-also" name="see-also">See Also</a></h2>
<ul>
<li>as you can see from example, pattern goes hand in hand with components.
  since actors update one domain at a time, splitting into components also
  conveniently lets you slice an actor into pieces that you can order to be
  cache friendly.</li>
</ul>
<p>don&#x2019;t need components to use this! even code totally unrelated to main game
  objects can still benefit from cache opt.</p>
<ul>
<li>
<p>classic presentation that got lot of people more aware of this is: http://research.scee.net/files/presentations/gcapaustralia09/Pitfalls_of_Object_Oriented_Programming_GCAP_09.pdf</p>
</li>
<li>
<p>around the same time, very influential blog post http://gamesfromwithin.com/data-oriented-design</p>
</li>
<li>
<p>pattern usually takes advantage of "flat array of objects of same kind". if
  need to create and destroy them while doing that, see "object pool".</p>
</li>
<li>
<p>artemis (http://gamadu.com/artemis/) is well-known framework using pure-id entities</p>
</li>
</ul>
<h2><a href="#random-notes" name="random-notes">random notes</a></h2>
<p>used to bit pack because memory was limited. then had enough memory that speed
mattered more and decoding was too expensive. now memory is effectively expensive again (have plenty, but slow to get to it), so worth it to bit pack again.</p>
<p>talk about how sometimes you <em>don&#x2019;t</em> want stuff on one cache line. if accessing on multiple threads, may be better to split.</p>
<p class="footer">&copy; 2009-2013 Bob Nystrom</p>
</div>
</body>
<script src="jquery-1.10.1.min.js"></script>
<script src="script.js"></script>
</html>
